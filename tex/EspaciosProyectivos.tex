\chapter{Espacio proyectivo y variedades proyectivas}
%En este capítulo usaremos la abreviatura "epro".
\label{epro}
\epigraph{``\ti{Nadie entre aquí que no sepa Geometría}''}{Frontispicio de la Academia de Platón}
\section{El espacio proyectivo}
Sea $E$ un $\K$--espacio vectorial arbitrario.

Podemos aproximarnos de dos formas distintas a la noción de ``\tbi[espacio!proyectivo]{espacio proyectivo}'', como veremos, ambas aproximaciones son equivalentes, de modo que las confundiremos cuando nos convenga. Cabe destacar que la segunda de estas aproximaciones tiene especial interés desde el punto de vista de la \tbi{topología}, por estar basada en conjuntos cociente, pero esos asuntos se salen del alcance de estas notas.
\subsection{Primera aproximación}
Antes de comenzar, cabe mencionar que para referirnos a los espacios vectoriales, a veces usaremos el término ``\tbi[espacio!lineal]{espacio lineal}''.
\begin{defi}[Espacio proyectivo]
	\label{epro_def_espacioProyectivo1}
	Se define el \tbi[espacio!proyectivo]{espacio proyectivo} asociado al espacio vectorial $E$ como el conjunto de los subespacios vectoriales de $E$ con dimensión $1$. Usualmente lo denotaremos por $\proy(E)$.
\end{defi}
Esta definición, presentada así, es como un diamante en bruto que debemos pulir un poco si lo que pretendemos es extraer algo útil de ella, motivo por el cual presentamos el siguiente concepto.
\begin{defi}[Rayo]
	\label{epro_def_rayo}
	Sea $u\in E\smz$, se denomina \tbi{rayo} engendrado por $u$ al conjunto de todos los vectores proporcionales a $u$, es decir
	\begin{equation*}
		\class{u}:\equals{def.}\{\lambda u\tq \lambda\in\K\}
	\end{equation*} 
\end{defi}
Esta última definición es pertinente, ya que, como recordamos (o no) todo subespacio vectorial $U$ de dimensión $1$ posee una base formada por un único vector (llamémosle $u$), o, dicho de otra manera, $U$ está generado por un único vector $u$. Es decir, todos los vectores que conforman $U$ son las combinaciones lineales de $u$, o sea, el rayo engendrado por $u$. ¿Y a qué viene todo esto? Pues a que podemos definir el espacio proyectivo asociado a un espacio lineal en términos de rayos (suena mucho mejor). En efecto
\begin{equation*}
	\proy(E):\equals{def.}\{\class{u}\tq u\in E\smz\}
\end{equation*}
Como el lector ya habrá advertido, el espacio proyectivo es un conjunto de rayos, es por este motivo que a los rayos usualmente se les llama \tbi[punto!proyectivo]{puntos proyectivos}.

Es importante tener siempre presente que los vectores \tb{no} son elementos del espacio proyectivo, confundir un vector $u\in E$ con su rayo engendrado $\class{u}\in\proy(E)$ está tipificado como delito de alta traición en el código penal proyectivo, y desencadenará la ira de Zeus.
\begin{obs}[Casos extremos]
	\label{epro_obs_casosExtremos}
	Antes de continuar, presentemos algunos casos curiosos, pero no demasiado exóticos.
	\begin{enumerate}
		\item Si $E=\zset$ entonces, por definición, $\proy(E)=\emptyset$, ya que no hay subespacios de dimensión $1$.
		\item Si $\dim(E)=1$, entonces $\proy(E)$ consta de un único elemento, el rayo generado por el vector de una base de $E$, es decir, cualquier vector no nulo.\qedhere
	\end{enumerate}
\end{obs}
\subsection{Segunda aproximación}
La definición \ref{epro_def_espacioProyectivo1} tiene una traducción natural en términos de relaciones de equivalencia y conjuntos cociente, que es la que pasamos a comentar aquí.
\begin{defi}[Relación de proporcionalidad]
	\label{epro_def_proporcionalidad}
	Se comprueba inmediatamente que la relación $\mc{R}$ definida en $E\smz$ como
	\begin{equation*}
		u\mc{R}v\siidef \text{hay un } \lambda\in\K\smz\text{ tal que } u = \lambda v
	\end{equation*}
	es de equivalencia, siendo la clase de equivalencia de un vector $u$ el conjunto de todos los proporcionales a él (excluyendo el vector nulo), es decir, el rayo engendrado por $u$ excepto el vector cero, a veces llamaremos ``\tbi{quasirayo} generado por $u$'' a este conjunto.
\end{defi}
La clase de un vector $u\in E$ según la relación de equivalencia definida en \ref{epro_def_proporcionalidad} será denotada por $u\mc{R}$. Y, como ya adelantamos
\begin{equation*}
	u\mc{R}=\class{u}\smz
\end{equation*}
Una vez hechos todos los preliminares, podemos redefinir el espacio proyectivo en términos del conjunto cociente engendrado por la relación de equivalencia que acabamos de presentar.
\begin{defi}[Espacio proyectivo]
	\label{epro_def_espacioProyectivo2}
	Definimos espacio proyectivo asociado a $E$ como el conjunto de las clases de equivalencia de $\mc{R}$, es decir, el conjunto cociente $\frac{E\smz}{\mc{R}}$.
\end{defi}
\subsection{Equivalencia de las aproximaciones}
Veamos ahora que, intuitivamente, podemos confundir ambas aproximaciones a la noción de espacio proyectivo, estableciendo una biyección ``natural'' entre los conjuntos resultantes de las definiciones \ref{epro_def_espacioProyectivo1} y \ref{epro_def_espacioProyectivo2}. La aplicación ``natural'' entre ambos conjuntos es la de asociar al quasirayo engendrado por un vector su rayo correspondiente, es decir
\begin{equation*}
	\begin{array}{cc}
	\Phi:&\frac{E\smz}{\mc{R}}\to\proy(E)\\
	&u\mc{R}\mapsto\class{u}
	\end{array}
\end{equation*}
Ver que efectivamente es una biyección y que está bien definida es un ejercicio fácil que se deja al pobre e incauto lector.
\subsection{Proyección canónica}
Una forma muy útil de relacionar el espacio proyectivo asociado a $E$ y el propio espacio lineal $E$, es mediante la llamada \tbi[proyección!canónica]{proyección canónica}, que es la aplicación (evidentemente sobreyectiva y potencialmente no inyectiva) que a cada vector le asocia su rayo engendrado, o sea
\begin{equation*}
	\begin{array}{cc}
	\pi:&E\smz\to\proy(E)\\
	&u\mapsto\class{u}\equiv u\mc{R}
	\end{array}
\end{equation*}
\section{Variedades proyectivas}
Como es típico en el álgebra (y en las matemáticas en general), trataremos de estudiar los subconjuntos de una determinada ``estructura'' que mantienen dicha ``estructura''.

En este caso, estudiaremos las \tbi[variedad!proyectiva]{variedades} o \tbi[subespacio!proyectivo]{subespacios} de espacios proyectivos. Este es un concepto que puede resultar confuso en una primera lectura, pero que es de importancia crucial.
\begin{defi}[Variedad proyectiva]
	\label{epro_def_variedades}
	Dado un subconjunto $X$ de un espacio proyectivo $\proy(E)$, se dirá que $X$ es una variedad proyectiva de $\proy(E)$ si existe una variedad lineal de $E$, a la que llamaremos $\widehat{X}$, de manera que el espacio proyectivo asociado a $\widehat{X}$ coincide con $X$. Escrito de otra forma
	\begin{equation*}
		X=\proy(\widehat{X})=\pi(\widehat{X}\smz)
	\end{equation*}
\end{defi}

El siguiente lema demuestra que hay dos enfoques equivalentes a la idea de variedad proyectiva.
\begin{lem}[Caracterización de las variedades]
	\label{epro_lem_caracterizacionVariedades}
	$X$ es variedad proyectiva si y solo si $\pi^{-1}(X)\cup\zset$ es un subespacio vectorial de $E$.
\end{lem}
\begin{proof} Veamos ambas implicaciones, al estilo de la vieja escuela.
\begin{itemize}
	\item[$\bra$]Como $X$ es una variedad proyectiva, por definición, hay una variedad lineal $\widehat{X}$ de manera que $\pi(\widehat{X}\smz)=X$.
	
	Nuestra estrategia consistirá en demostrar que $\pi^{-1}(X)\cup\zset=\widehat{X}$, con lo que ya tendríamos que $\pi^{-1}(X)\cup\zset$ es una variedad lineal. Veamos pues que esto es cierto. Si recordamos, $\pi(\widehat{X}\smz)=X$, de modo que, aplicando $\pi^{-1}$ a ambos lados tenemos que
	\begin{equation*}
		\pi^{-1}(\pi(\widehat{X}\smz))=\pi^{-1}(X)
	\end{equation*}
	Además (y, aunque lo parezca, no es algo trivial) $\pi^{-1}(\pi(\widehat{X}\smz))=\widehat{X}\smz$.
	
	En efecto, dado $x\in\pi^{-1}(\pi(\widehat{X}\smz))$, se tiene que $\pi(x)\in\pi(\widehat{X}\smz)=\{\class{y}\tq y\in\widehat{X}\smz\}$, luego hay un $y_0\in\widehat{X}\smz$ de manera que $\class{y_0}=\class{x}=\pi(x)$, por lo que habrá un $\lambda_0\in\K$ de forma que $x=\lambda_0y_0$, de donde se deduce que $x\in\widehat{X}\smz$. Por otra parte, dado, $x\in\widehat{X}\smz$, como $\pi(x)=\class{x}=\{\lambda x\tq \lambda\in\K\}$ tenemos que
	\begin{equation*}
		\pi^{-1}(\{\pi(x)\})= \{y\in E\smz\tq\pi(y)=\class{y}\in\{\pi(x)\}\}=\{y\in E\smz\tq y=\lambda x\text{ con }\lambda\in\K\}
	\end{equation*}
	con lo que, evidentemente, $x\in\pi^{-1}(\{\pi(x)\})\subset\pi^{-1}(\pi(\widehat{X}\smz))$.
	
	En definitiva, hemos demostrado que $\pi^{-1}(\pi(\widehat{X}\smz))=\widehat{X}\smz$, por tanto, $\widehat{X}\smz=\pi^{-1}(X)$, uniendo el vector nulo obtenemos que $\widehat{X}=\pi^{-1}(X)\cup\zset$ (como queríamos).
	\item[$\bla$] Si $\pi^{-1}(X)\cup\zset$ es un subespacio vectorial, su proyectivo asociado será $\pi(\pi^{-1}(X))=X$ (la igualdad se da por la sobreyectividad de $\pi$), con lo que hemos encontrado una variedad lineal de $E$ de forma que $X$ es su espacio proyectivo asociado, luego, por la definición de variedad proyectiva, hemos terminado.\qedhere
\end{itemize}
\end{proof}
Del lema anterior se deduce que los subespacios vectoriales de $E$ y los subespacios proyectivos de $\proy(E)$ están en biyección, siendo este un resultado análogo (en cierto sentido) al llamado \ti{lema de la correspondencia} de la teoría de grupos y anillos. Estudiemos más a fondo este hecho.
\begin{obs}[Lema de la correspondencia]
	Sea $\mc{P}$ el conjunto de las variedades proyectivas de $\proy(E)$. Asimismo sea el conjunto $\mc{L}$ compuesto por las variedades lineales de $E$. Es claro, por la definición de variedad proyectiva \eqref{epro_def_variedades} y por el lema \ref{epro_lem_caracterizacionVariedades}, que la siguiente aplicación es una biyección
	\begin{equation*}
	\begin{array}{cc}
	\Phi:&\mc{P}\to\mc{L}\\
	&X\mapsto\pi^{-1}(X)\cup\zset
	\end{array}
	\end{equation*}
	Aunque trivial, es recomendable recordar que las biyecciones preservan las contenciones, es decir
	\begin{equation*}
	X\subset Y \sii \pi^{-1}(X)\cup\zset\subset \pi^{-1}(Y)\cup\zset
	\end{equation*}
	Esta tontuna es útil, pues nos permite afirmar que el espacio proyectivo asociado a un subespacio $U$ de $E$, es un subespacio proyectivo de $\proy(E)$ (y viceversa, por supuesto).
\end{obs}
\subsection{Operaciones con variedades proyectivas}
Tras estas observaciones, estamos en condiciones de abordar dos problemas elementales pero importantes. Estos son
\begin{enumerate}
	\item Determinar si la intersección de variedades proyectivas es una variedad proyectiva.
	\item Obtener una descripción explícita de los elementos que conforman la mínima variedad proyectiva que contiene a un subconjunto del espacio proyectivo.
\end{enumerate}
Pasemos a resolverlos sin más dilación.
\begin{lem}[Intersección de variedades proyectivas]
	\label{epro_lem_interseccionVariedades}
	Sea la familia de variedades proyectivas $\{X_i\tq i\in I\}$, se tiene que la intersección $X=\bigcap_{i\in I}X_i$ es una variedad proyectiva.
	
	Además, se verifica $\widehat{X}=\bigcap_{i\in I}\widehat{X_i}$, es decir, el espacio vectorial subyacente a la intersección de variedades, es la intersección de los espacios vectoriales asociados a las variedades que interseco.
\end{lem}
\begin{proof}
	Debemos demostrar que $\bigcap_{i\in I}X_i$ es variedad proyectiva. Esto pasa, por el lema \ref{epro_lem_caracterizacionVariedades}, si y solo si $\pi^{-1}\left(\bigcap_{i\in I}X_i\right)\cup\zset$ es un espacio vectorial. Si tenemos suerte, se cumplirá que $\pi^{-1}\left(\bigcap_{i\in I}X_i\right)=\bigcap_{i\in I}\pi^{-1}(X_i)$. En efecto, tenemos suerte, ya que esta es una propiedad que cumplen las imágenes inversas de cualquier función.
	
	Así pues, por ser cada $X_i$ una variedad proyectiva y, por tanto, $\pi^{-1}(X_i)\cup\zset$ un subespacio vectorial, unido al hecho de que la intersección arbitraria de espacios vectoriales continúa siendo un espacio vectorial, se tiene que $\pi^{-1}\left(\bigcap_{i\in I}X_i\right)\cup\zset$ es un subespacio vectorial, como queríamos demostrar.
	
	El \ti{además} se obtiene muy fácilmente. En efecto
	\begin{equation*}
		\widehat{X}=\pi^{-1}\left(\bigcap_{i\in I}X_i\right)\cup\zset=\bigcap\pi^{-1}(X_i)\cup\zset=\bigcap_{i\in I}\widehat{X_i}\qedhere
	\end{equation*}
\end{proof}
Con el lema \ref{epro_lem_interseccionVariedades} queda resuelto el primer problema planteado en esta sección. Pasemos ahora a estudiar la noción de variedad proyectiva engendrada por un subconjunto cualquiera $A$ de $\proy(E)$ así como sus propiedades.
\begin{defi}[Variedad engendrada por un subconjunto]
	\label{epro_def_variedadEngendrada}
	Sea $A\subset\proy(E)$ no vacío. Se define la \tbi[variedad!proyectiva engendrada]{variedad proyectiva engendrada por $A$} como el menor subespacio proyectivo que contiene a $A$. A esta se la denotará por $\engen{A}$.
\end{defi}
Vamos a demostrar la existencia de dicha variedad construyéndola mediante un truco muy habitual en matemáticas.
\begin{obs}[Existencia de la variedad engendrada]
	\label{epro_obs_variedadEngendrada}
	Sea $\mc{L}$ la familia de las variedades proyectivas de $\proy(E)$ que contienen a $A$. Es trivial demostrar que $\bigcap_{X\in\mc{L}}X$ es la menor variedad proyectiva que contiene a $A$.
	
	Que es variedad proyectiva es evidente por el lema \ref{epro_lem_interseccionVariedades}. Es la menor variedad, ya que, dada cualquer otra variedad $Y$ que contenga a $A$, esta pertenecerá a la familia $\mc{L}$, por lo que su intersección estará contenida en $Y$.
\end{obs}
La observación \ref{epro_obs_variedadEngendrada} demuestra la existencia de la variedad engendrada de la misma forma que demostramos la existencia de un subespacio vectorial engendrado por un conjunto, o del subgrupo generado por un conjunto, lo que deja claro la importancia de este truco. Sin embargo, esta demostración no nos da una descripción explícita de los elementos de la variedad.

Una forma de resolver este problema es, a la luz del lema \ref{epro_lem_caracterizacionVariedades}, encontrar la variedad lineal asociada a la variedad engendrada.
\begin{lem}[Variedad lineal asociada a una variedad engendrada]
	Se tiene que \[\widehat{\engen{A}}=\lengen{\pi^{-1}(A)}\]
	Es decir, la variedad lineal asociada a la variedad proyectiva engendrada por $A$ es aquella que engendra la ``preproyección'' de $A$ sobre $E$.
\end{lem}
\begin{proof}
	Procedamos por doble contención
	\begin{itemize}
		\item[\bsupset] Como $A\subset\engen{A}$ entonces $\pi^{-1}(A)\subset\widehat{\engen{A}}$, luego $\lengen{\pi^{-1}(A)}\subset\widehat{\engen{A}}$.
		\item[\bsubset]Como $\pi^{-1}(A)\subset\lengen{\pi^{-1}(A)}\smz$, aplicando $\pi$ se tiene (por su sobreyectividad) que $A\subset \pi(\lengen{\pi^{-1}(A)}\smz)$. Al ser $\lengen{\pi^{-1}(A)}$ un subespacio vectorial, su proyectivizado será una subvariedad proyectiva $X$, en concreto, $X=\pi(\lengen{\pi^{-1}(A)}\smz)$. Como dedujimos al principio, $A\subset X$, luego tenemos la desigualdad
		\begin{equation*}
			A\subset\engen{A}\subset X=\pi(\lengen{\pi^{-1}(A)}\smz)
		\end{equation*}
		y aplicando $\pi^{-1}$ obtenemos
		\begin{equation*}
			\pi^{-1}(\engen{A})=\widehat{\engen{A}}\smz\subset\lengen{\pi^{-1}(A)}\smz\qedhere
		\end{equation*}
	\end{itemize}
\end{proof}
El lema anterior nos da una descripción explícita de los elementos de la variedad engendrada por un conjunto, basta aplicar la proyección canónica para obtener
\begin{equation}\label{epro_eq_explicitaEngendrados}
	\engen{A}=\pi(\lengen{\pi^{-1}(A)}\smz)
\end{equation}
Tengamos especialmente en cuenta el caso de las variedades engendradas por conjuntos finitos.
\begin{exa}[Variedades engendradas por conjuntos finitos]
	\label{C1_exa_generadoresFinitos}
	Sea $A=\{p_1,\dots,p_n\}$, denotaremos $\engen{p_1,\dots,p_n}:=\engen{A}$, escogiendo un representante $u_i\in E\smz$ arbitrario para cada $p_i$ obtenemos, por la ecuación \eqref{epro_eq_explicitaEngendrados}, que
	\begin{equation*}
		\engen{p_1,\dots,p_n}=\pi(\lengen{u_1,\dots,u_n}\smz)\qedhere
	\end{equation*}
\end{exa}
\section{Dimensiones y fórmula de Grassmann}
Prosiguiendo en nuestra traducción de los conceptos del mundo vectorial al idioma proyectivo introduciremos el concepto de dimensión de un espacio proyectivo y deduciremos la llamada fórmula de Grassmann.

\subsection{Dimensiones y fórmula de Grassmann}
Es importante tener claro que los espacios proyectivos \tb{no} son espacios vectoriales, ya que no hemos definido la noción de suma de rayos o producto de rayos por escalares. Sin embargo, parece razonable extender la noción de dimensión a los espacios proyectivos.

Intuitivamente, al considerar las rectas vectoriales como puntos estamos, entre comillas, perdiendo un ``grado de libertad''. Esta idea es recogida por la siguiente definición. 
\begin{defi}[Dimensión de un Espacio Proyectivo]
	\label{epro_def_dimension}
	Si $E$ es un $\K$--espacio vectorial de dimensión $n$, se define la \tbi{dimensión} de $\proy(E)$ como $n-1$. Es decir, la \tbi{codimensión} de un espacio proyectivo respecto de su espacio lineal asociado es $1$.
\end{defi}
Usualmente nos referiremos a los espacios proyectivos de dimensión $1$ como \tbi[recta!proyectiva]{rectas proyectivas}, a los de dimensión $2$ como \tbi[plano!proyectivo]{planos proyectivos} y a los de dimensión $3$ como \tbi[espacio!proyectivo]{espacios proyectivos}.

Es importante distinguir algunos casos extremos que pueden parecer chocantes.
\begin{obs}[Casos extremos]
	\label{epro_obs_casosExtremosDim}
	\begin{enumerate}
		\item Si $E$ es un espacio vectorial de dimensión $1$, entonces $\proy(E)$ tiene dimensión nula, lo cual tiene sentido al estar conformado por un solo punto.
		\item Si $E =\zset$, es decir, un espacio vectorial de dimensión $0$, resulta que su espacio proyectivo tiene dimensión $-1$.\qedhere
	\end{enumerate}
\end{obs}
Estamos ahora en condiciones de presentar el ejemplo de \ti{espacio canónico}, cuya notación no hubiéramos entendido hasta ahora.
\begin{exa}[Espacio canónico]
	\label{C1_exa_espacioCanonico}
	El espacio proyectivo asociado a un espacio vectorial de la forma $E=\K^{n+1}$ se denomina \tbi[espacio!canónico]{espacio canónico} y se denota por $\proy^n:=\proy(E)$
\end{exa}
Una igualdad recurrente en matemáticas es la llamada \tbi[fórmula!de Grassmann]{fórmula de Grassmann}, que se presenta con diversas versiones en áreas tan dispersas de las matemáticas como la teoría de conjuntos, la probabilidad, la teoría de grupos, el álgebra lineal,... Como no podía ser de otra manera, también está presente en los espacios proyectivos.
\begin{theo}[Fórmula de Grassmann. Teorema de la incidencia]
	\label{C1_teo_grassmann}
	Sean $X,Y$ dos variedades proyectivas. Se tiene que (nótese el abuso de notación)
	\begin{equation*}
		\dim(\engen{X,Y})=\dim(X)+\dim(Y)-\dim(X\cap Y)
	\end{equation*}
\end{theo}
\begin{proof}
	Apoyándonos en la fórmula de Grassmann para espacios vectoriales, sale fácilmente. En efecto, como  \[\dim(\engen{X,Y})=\dim(\widehat{\engen{X,Y}})-1\] y además \[\dim(X)+\dim(Y)-\dim(X\cap Y)=\dim(\widehat{X})-1+\dim(\widehat{Y})-1-\dim(\widehat{X\cap Y})+1\] por la fórmula de Grassmann en espacios vectoriales sabemos que los dos miembros de la derecha de sendas igualdades coinciden.
\end{proof}
Este teorema arroja un corolario importante, del que debemos extraer la idea de que en los espacios proyectivos las cosas se cortan muy fácilmente. Es por esto que se conoce a la geometría proyectiva como \ti{geometría de la incidencia}.
\begin{cor}[Hiperplanos y rectas]
	\label{C1_cor_rectaHiperplano}
	Una recta y un hiperplano proyectivos siempre se cortan.
\end{cor}
\begin{proof}
	Basta sustituir las dimensiones en la fórmula de Grassmann teniendo en cuenta que $\dim(\proy(E))\geq\dim(\engen{X,Y})$, despejando se concluye que $\dim(\engen{X,Y})\geq 0$, y, por tanto, hay al menos un punto común.
\end{proof}
\section{Referencias proyectivas}
En esta sección trataremos de extrapolar el concepto de \ti{base} de un espacio vectorial a los espacios proyectivos.

Sea $E$ un $\K$--espacio vectorial cualquiera de dimensión $n+1$. Sabemos por álgebra lineal que, dada $\mc{B}:=\{e_0,\dots,e_n\}$ una base de $E$, cualquier vector $x\in E$ puede escribirse de manera única como combinación lineal de los vectores que conforman la base, es decir, para ciertos $\lambda_i$ con $i\in\{0,\dots,n\}$ se tiene:
\begin{equation}
\label{C1_eq_combinacionLineal}
x=\sum_{i=0}^{n}\lambda_ie_i\stackrel{\textrm{not.}}{\equiv}(\lambda_0,\dots,\lambda_n)_{\mc{B}}\stackrel{\textrm{not.}}{\equiv}\mc{B}X
\end{equation}
Nótese que la tercera equivalencia de la ecuación~\eqref{C1_eq_combinacionLineal}, es un mero abuso de notación muy extendido para que esta sea más compacta.

Volviendo al mundo proyectivo, queremos encontrar cierta colección de puntos proyectivos en función de los cuales poder escribir todos los demás. 
\subsection{Coordenadas Homogéneas}
\label{C1_coordenadasHomogeneas}
Si tomamos un punto proyectivo $x:=\class{u}\in\proy(E)$, por la ecuación~\eqref{C1_eq_combinacionLineal} podremos escribir:
\begin{equation}
	\label{C1_eq_coordenadasHomogeneas}
	x:\class{u}=\class{(\lambda_0,\dots,\lambda_n)_{\mc{B}}}:\stackrel{\textrm{not.}}{\equiv}(\lambda_0:\dots:\lambda_n)
\end{equation}
Al último miembro de la ecuación~\eqref{C1_eq_coordenadasHomogeneas} se le llama \ti{escritura de $x$ en coordenadas homogéneas}.

Nótese que, \tb{fijada una base}, las coordenadas homogéneas de un punto proyectivo son únicas salvo proporcionalidad, ya que si se toma un representante $u'$ distinto del rayo vectorial, su escritura respecto de la base $\mc{B}$ será proporcional a la de $u$ (los representantes son múltiplos entre sí).

Con esto podría decirse que hemos cumplido el objetivo de la sección, ya que, dada una base de $E$, podemos escribir en función de ella a cualquier punto proyectivo.

Sin embargo, estamos creando una referencia en base a otra ya existente, lo cual no es muy recomendable salvo si nuestra referencia base (base del espacio vectorial) es \ti{estándar} o \ti{canónica}, lo cual sólo ocurre en contadas ocasiones, por ejemplo, en los espacios canónicos.
\subsection{Referencias Proyectivas}
Para evitar los problemas derivados de la aproximación presentada en el apartado anterior, debemos concentrarnos en la idea de que lo que debemos hacer es encontrar una colección de elementos del espacio proyectivo, en función de los cuales poder escribir todos los demás. A ese conjunto de puntos lo llamaremos \ti{referencia proyectiva}.
\begin{defi}[Independencia Proyectiva]
	\label{C1_def_independenciaProyectiva}
	Sea un conjunto $\{p_0,\dots,p_r\}\subset\proy(E)$, diremos que son \ti{proyectivamente independientes} si ninguno de ellos está en la variedad proyectiva engendrada por los restantes.
\end{defi}
Con un poco de trabajo adicional extraemos la siguiente caracterización de la independencia proyectiva.
\begin{lem}[Caracterización de la Indepencia Proyectiva]
	\label{C1_lem_caracterizacionIndependencia}
	Un conjunto de puntos proyectivos es proyectivamente independiente si y solo si sus representantes (cualesquiera) son linealmente independientes, sin depender de la elección de los mismos. 
\end{lem}
\begin{proof}
	Decir que los representantes son linealmente independientes es equivalente a decir que, dado un de ellos, no puede ser expresado como combinación lineal de los restantes y por ende no se encuentra en la variedad lineal engendrada por estos. Por la ecuación~\eqref{C1_eq_explicitaEngendrados} sabemos que:
	\[u_i\not\in\lengen{u_0,\dots,u_{i-1},u_{u+1},\dots,u_{r}}\sii\class{p_i}\not\in\engen{p_0,\dots,p_{i-1},p_{i+1},\dots,p_r}\]
\end{proof}
\begin{obs}[Base Inducida]
	\label{C1_obs_baseInducida}
	En un espacio proyectivo de dimensión $n$, podemos escoger (como mucho) un conjunto de $n+1$ puntos proyectivamente independientes ya que, para cualquier elección de representantes de estos puntos, se obtendrían $n+1$ vectores linealmente independientes del espacio vectorial asociado $E$, de dimensión $n+1$, en el cual estos vectores, por definición formarían una base a la que llamaremos \ti{base inducida}.
\end{obs}
Hay un gran problema con la definición \ref{C1_def_independenciaProyectiva}, y es que, dados $n+1$ puntos proyectivos, inducimos una familia de bases de $E$ demasiado ``grande''. Con grande nos referimos a que no solo inducimos una base junto con todas las proporcionales a ella (resultantes de aplicarle el mismo factor de escala a todos sus vectores), sino muchas más.
\begin{obs}[No Unicidad de la Base Inducida]
	\label{C1_obs_noUnicidadBase}
	Dada una elección de representantes $\{u_o,\dots,u_n\}$ que son una base de $E$, entonces, el conjunto de representantes $\{\lambda_0u_0,\dots,\lambda_nu_n\}$, con $\lambda_i\in\K^*$ también conforma una base de $E$.
\end{obs}

Para solucionar este problema deberemos añadir alguna restricción más a la definición de base inducida.
\begin{defi}[Referencia Proyectiva]
	\label{C1_def_refereciaProyectiva}
	Dado un espacio proyectivo de dimensión $n$, una \ti{referencia proyectiva} es un conjunto \tb{ordenado} $\mf{R}$ de $n+2$ puntos de tal forma que cada $n+1$ de ellos son proyectivamente independientes. 
\end{defi}

A pesar de ser una referencia proyectiva un conjunto ordenado normalmente lo escribiremos con la notación usual para conjuntos.

\begin{obs}[Reordenación]
	\label{C1_obs_reordenacionReferencias}
	Dada una referencia $\mf{R}$, cualquier reordenación de la misma sigue siendo referencia proyectiva.
\end{obs} 

\begin{exa}[Referencias Proyectivas en Dimensiones Bajas]
	\label{C1_exa_dimensionesBajas}
	\begin{enumerate}
		\item En caso de querer dar una referencia de la recta proyectiva deberemos elegir tres puntos proyectivamente independientes dos a dos.
		\item Si queremos referenciar el plano proyectivo deberemos dar lo que se llama \ti{triangulo de referencia}, es decir, una elección de cuatro puntos proyectivamente independientes tres a tres. Esto es equivalente a decir que, para cualquier elección de tres puntos, estos formen un triángulo no degenerado.
		\item La misma idea se extrapola al espacio proyectivo, donde habría que escoger un \ti{tetraedro de referencia}.
	\end{enumerate}
	Para dimensiones más altas se hablará de \ti{hipertetraedros de referencia}.
\end{exa}
\subsection{Base Asociada a una Referencia Proyectiva}
Siguiendo la idea de las observaciones \ref{C1_obs_baseInducida} y \ref{C1_obs_noUnicidadBase} vamos a estudiar las propiedades de las llamadas \ti{bases asociadas} a referencias proyectivas.
\begin{defi}[Base Asociada]
	\label{C1_def_baseAsociada}
	Una base $\mc{B}$ de $E$ se dice \ti{asociada} a la referencia proyectiva $\mf{R}$ si sus vectores son representantes de los $n+1$ primeros puntos proyectivos, y además, la suma de sus vectores es representante del último de los puntos.
\end{defi}
Nótese que una base asociada no es más que una base inducida con una pequeña restricción más, con la suerte de que esta es fundamental para solucionar el problema de la no unicidad salvo proporcionalidad, tal y como muestra el siguiente teorema, cuya demostración contituye un \tb{método de construcción de bases asociadas}.
\begin{theo}[Unicidad de la Base Asociada]
	\label{C1_teo_unicidadBase}
	Para cada referencia proyectiva $\mf{R}$ de $\proy(E)$ hay una base asociada única salvo un factor no nulo común a todos los elementos de la base.
\end{theo}
\begin{proof}
	\begin{enumerate}
		\item Probemos la \tb{existencia} de dicha base. Dada una referencia proyectiva $\mf{R}$, tomemos representantes de cada uno de los puntos. Por ser $\mf{R}$ referencia proyectiva y por el lema \ref{C1_lem_caracterizacionIndependencia} los representantes de los $n+1$ primeros puntos forman una base de $E$, y, por ende, el representante del último punto puede escribirse como combinación lineal de los anteriores. Denotando por $u_i$ al representante escogido para el $i$--ésimo punto se tiene que:
		\[u_{n+1}=\sum_{i=0}^{n}a_iu_i\]
		Veamos que $\mc{B}=\{a_iu_i\tq 0\leq i\leq n\}$ es una base de $E$ y además sus vectores son representantes de los $n+1$ primeros puntos de $\mf{R}$. Esto es debido a que ninguno de los coeficientes $a_i$ es nulo. Si alguno lo fuera, por ejemplo $a_0=0$, se tendríamos la relación:
		\[
		u_{n+1}=\sum_{i=1}^{n}a_iv_i\in\lengen{v_1,\dots,v_n}
		\] Lo cual va contra la hipótesis de independencia proyectiva. Además, la suma de sus vectores es un representante del último punto de la referencia. Luego $\mc{B}$ es base asociada a $\mf{R}$.
		\item Para demostrar la unicidad supongamos la existencia de dos bases asociadas:
		\begin{gather*}
			\mc{B}:=\{u_0,\dots,u_n\}\\
			\mc{B}':=\{u_0',\dots,u_n'\}
		\end{gather*}
		Instantáneamente se ve que $u_i'=u_i\lambda_i$ para algún $\lambda\in\K^*$ para todos los $i\in\{0,\dots,n\}$, ya que sino no serían representantes de los primeros elementos de la referencia. Además, se debe dar la condición:
		\[\class{\sum_{i=0}^{n}u_i}=\class{\sum_{i=0}^{n}u_i'}\] y, por lo tanto, las sumas deben ser proporcionales, de lo que se desprende:
		\[\sum_{i=0}^{n}u_i'=\sum_{i=0}^{n}u_i\lambda_i=\lambda\sum_{i=0}^{n}u_i\]
		Es decir, las bases son proporcionales.
	\end{enumerate}
\end{proof}
La comprobación de que un conjunto ordenado de $n+2$ puntos es referencia proyectiva puede ser muy tediosa ya que consiste en realizar $\binom{n+2}{n+1}=n+2$ determiantes de orden $n+1$. El lema \ref{C1_lem_comprobacionReferencias} es extramadamente útil pues reduce esta comprobación al cálculo de un determinante de orden $n+1$ y a la inversión de una matriz de orden $n+1$.
\begin{lem}[Comprobación de Referencias Proyectivas]
	\label{C1_lem_comprobacionReferencias}
	Para comprobar que $n+2$ puntos proyectivos $x_i=\class{v_i}$ conforman una referencia proyectiva basta comprobar las siguientes condiciones:\begin{enumerate}
		\item Los $n+1$ primeros puntos son proyectivamente independientes.
		\item Al escribir $v_{n+1}=\sum_{i=0}^{n}\lambda_iv_i$ se tiene que $\lambda_i\not=0\ \forall\ 0\leq i\leq n$
	\end{enumerate}
\end{lem}
\begin{proof}
	Si se cumplen las condiciones del enunciado se tiene que $\{\lambda_0u_0,\dots,\lambda_nu_n\}$ es una base de $E$. Si a este conjunto le añadimos $v_{n+1}$, sabemos por álgebra lineal que es un conjunto linealmente dependiente y un sistema de generadores de $E$. Por ende, alguno de los vectores del conjunto puede ponerse como combinación lineal de los demás, y extrayendo este elemento del conjunto, este seguirá siendo sistema de generadores. Obviamente, $v_{n+1}$ puede ponerse como combinación lineal de los demás, pero esto no nos ayuda. Lo interesante es, que como todos los coeficientes $\lambda_i$ son no nulos, podemos despejar cualquier $v_i$ de la ecuación, de esta forma:
	\[v_{n+1}=\sum_{i=0}^{n}\lambda_iv_i\sii v_i = \sum_{j\not=i,n+1}\frac{\lambda_j}{-\lambda_i}u_j+\frac{1}{\lambda_i}u_{n+1}\]
	Entonces podemos formar $\binom{n+2}{n+1}=n+2$ conjuntos diferentes de $n+1$ vectores, si todos ellos formaran bases habríamos terminado, pero esto es evidente, ya que son sistemas de generadores de $n+1$ elementos, es decir, bases.
\end{proof}
Para clarificar un poco las cosas se presenta el siguiente ejemplo.
\begin{exa}[Referencia de $\proy^2$]
	\label{C1_exa_basesAsociadas}
	En $\proy^2$ nos dan los puntos: \begin{gather*}a_0=(1:0:1),\ a_1=(0:2:1)\\a_2=(0:0:1),\ a_3=(1:-1:0)
	\end{gather*}
	
	Las coordenadas homogéneas vienen dadas según la base estándar de $\R^3$.
	
	Se pide estudiar si dichos puntos conforman una referencia proyectiva.
	
	Siguiendo el lema \ref{C1_lem_comprobacionReferencias} para ahorrarnos cálculos, vemos que los representantes de $a_0$, $a_1$ y $a_2$ son una base de $\R^3$
		\begin{equation*}
		u_0=(1,0,1),\ u_1=(0,2,1),\ u_2=(0,0,1)
		\end{equation*}
	En efecto, al calcular el determinante:
	\[\begin{vmatrix}
	1 & 0 & 1\\
	0 & 2 & 1\\
	0 & 0 & 1
	\end{vmatrix}\not= 0\]
	Ahora, tomando $u_3=(1,-1,0)$ como representante de $a_3$, bastaría resolver el sistema de ecuaciones lineales (que sabemos compatible determinado) dado por:
	\[\alpha u_0+\beta u_1 + \gamma u_2 = u_3\]
	Si la matriz columna solución no tiene ningún coeficiente nulo la colección de puntos original conforma una referencia proyectiva de base asociada dada por el método de construcción de bases asociadas (teorema \ref{C1_teo_unicidadBase}), es decir, la base asociada sería:\[\mc{B}=\{\alpha u_0,\beta u_1, \gamma u_2\}\]
	
	Con un poquito de magia se obtiene que:\[\alpha = 1,\ \beta = -\frac{1}{2},\ \gamma = -\frac{1}{2}\]
	Como no son todos nulos, los puntos originales conforman una referencia proyectiva.
	
	Una base asociada sería:
	\[
	\mc{B}=\left\{(1,0,1), \left(0,-1,-\frac{1}{2}\right),\left(0,0,-\frac{1}{2}\right)\right\}
	\]
	
	Como esta base es única salvo proporcionalidad, podríamos multiplicar todo por $2$ para que nos queda algo más bonito:
	\[
	\mc{B}'=\left\{(2,0,2), \left(0,-2,-1\right),\left(0,0,-1\right)\right\}
	\]
\end{exa}
Antes de continuar, fijemos una notación para referirnos a referencias proyectivas.

Dada una referencia proyectiva $\mf{R}$, la denotaremos por los puntos que la conforman de la siguiente manera:
\begin{equation}
\label{C1_eq_notacionReferencias}
\mf{R}=\{p_0,\dots,p_n;e\}
\end{equation}
Donde $e$ representa el último punto al que llamaremos \ti{punto unidad}.
\begin{defi}[Coordenadas Homogéneas respecto de una Referencia $\mf{R}$]
	\label{C1_def_coordenadasReferencia}
	Dado un punto proyectivo $p\in\proy(E)$ y una referencia proyectiva $\mf{R}$, se dice que $p=(x_0:\dots :x_n)_{\mf{R}}$ si, para cualquier elección de $u$ (representante del rayo $p$) y cualquier elección de base asociada $\mc{B}$ a $\mf{R}$, se tiene que
	\[u=\lambda(x_0,\dots,x_n)_{\mc{B}}\]
\end{defi}
Es evidente, por lo visto en la sección \ref{C1_coordenadasHomogeneas} y en el teorema \ref{C1_teo_unicidadBase}, que la definición \ref{C1_def_coordenadasReferencia} es sólida.
\section{Cambios de Referencia Proyectiva}
Cuando realizábamos cambios de base en álgebra lineal nos preguntábamos cuáles eran las relaciones entre las coordenadas de un vector respecto de una y otra base. Bajando al mundo proyectivo nos hacemos la misma pregunta. ¿Cómo cambian las coordenadas homogéneas de un punto al realizar cambios en la referencia proyectiva?

Sean dos referencias proyectivas $\mf{R}$ y $\mf{R}'$, las cuales tendrán sendas bases asociadas $\mc{B}$ y $\mc{B}'$ (únicas salvo múltiplos) (teorema \ref{C1_teo_unicidadBase}).

Sea un punto $x\in\proy(E)$. Es claro que podemos expresar este punto en coordenadas homogéneas respecto de la referencia $\mf{R}$ de la siguiente manera:
\[x=\class{u}=\class{(\alpha_0,\dots,\alpha_n)_\mc{B}}\]
Asimismo también es claro que $x$ admite una representación en términos de la referencia $\mf{R}'$:
\[x=\class{u}=\class{(\beta_0,\dots,\beta_n)_{\mc{B}'}}\]
Un problema que se presenta habitualmente es, conocida la representación de un vector respecto de cierta referencia $\mf{R}$, ¿cómo obtengo la representación respecto de otra referencia $\mf{R}'$ de mi elección?

Solucionemos este problema aplicando lo que ya sabemos de álgebra lineal. Antes de comenzar, fijemos notaciones:
\begin{gather*}
	u=\mc{B}X\equiv(\alpha_0,\dots,\alpha_n)_\mc{B}\\
	u=\mc{B}'X'\equiv(\beta_0,\dots,\beta_n)_{\mc{B}'}
\end{gather*}
donde los símbolos $\mc{B}$ y $\mc{B}'$ representan las matrices fila que contienen los vectores de las bases $\mc{B}$ y $\mc{B}'$ respectivamente. Asimismo, los símbolos $X$ y $X'$ representan las matrices columna de los coeficientes $\alpha_i$ (conocidos) y $\beta_i$ (desconocidos) respectivamente. Nótese que es esto es un abuso de notación, ya que no hemos definido el producto de dos matrices de estos tipos.

Como sabemos (\ref{A1_cambioBase}), se cumplen las llamadas ``ecuaciones del cambio de base'', que dicen:
\begin{equation*}
	X'=P^{-1}X
\end{equation*}
donde $P$ es la matriz cuyas columnas son las coordenadas de los vectores de la base $\mc{B}'$ respecto de la base $\mc{B}$. Así pues, basta poner $X'$ en ``formato de coordenadas'' para poder decir que hemos encontrado una representación (única salvo múltiplos) del punto $x$ en base a la referencia $\mf{R}'$. Es decir
\begin{equation}
	 \rho X'=P^{-1}X
\end{equation}
donde $\rho$ es simplemente la constante de proporcionalidad. Dado que podemos tomar múltiplos sin problema alguno y como
\begin{equation*}
	P^{-1}=\frac{1}{\det{P}}P^*
\end{equation*}
donde $P^*$ es la adjunta traspuesta definida en álgebra lineal, la ecuación de cambio de coordenadas entre referencias proyectivas puede escribirse como
\begin{equation}
	\rho' X'=P^*X
\end{equation}
Usualmente denotaremos $M=P^*$ a la matriz de cambio de coordenadas entre referencias.

Un ejemplo clarificará todos estos cambalaches.
\begin{exa}[Cambio de Referencia Proyectiva]
	Se considera el plano proyectivo $\proy^2$ y las referencias proyectivas:
	\begin{gather*}
		\mf{R}:=\{(2:0:-1),(1:-1:0),(1:-1:1);(1:0:-1)\}\\
		\mf{R}':=\{(1:1:1),(0:1:1),(1:0:1);(2:2:3)\}
	\end{gather*}
	Si queremos calcular las coordenadas homogéneas del punto $(2:2:2)$ respecto de $\mf{R}$ y $\mf{R'}$ deberemos tener en cuenta un par de cosas. La primera, es que las coordenadas homogéneas de todos los puntos escritos hasta ahora hace referencia a la base canónica de $\R^3$.
	
	Por ende, basta con calcular la matriz de cambio de base de la base canónica a las bases asociadas por $\mf{R}$ y $\mf{R}'$, lo cual es algo facilísimo (una vez obtenidas sendas bases).
	
	Como la obtención de las mismas no es el objetivo de esta sección, las presentaremos directamente, sin embargo, si uno no se fía, siempre puede acudir al ejemplo \ref{C1_exa_basesAsociadas} y al teorema \ref{C1_teo_unicidadBase}, donde se expone un método para calcular la base asociada a una referencia.
	\begin{gather*}
		\mc{B}_{\mf{R}}=\{(2,0,-1),(1,-1,0),(-1,1,-1)\}\\
		\mc{B}_{\mf{R}'}=\{(1,1,1),(0,1,1),(1,0,1)\}
	\end{gather*}
	Por lo tanto las matrices de cambio de base serán:
	\begin{gather*}
			P_{\mf{R}}=\begin{pmatrix}
				2 & 1 & -1\\
				0 & -1 & 1\\
				-1 & 0 & -1
			\end{pmatrix}\leadsto P_{\mf{R}}^{-1}=\begin{pmatrix}
			\frac{1}{2} & \frac{1}{2} & 0 \\
			-\frac{1}{2} & -\frac{3}{2} & -1 \\
			-\frac{1}{2} & -\frac{1}{2} & -1
		\end{pmatrix}\\
			P_{\mf{R}'}=\begin{pmatrix}
				1 & 0 & 1\\
				1 & 1 & 0\\
				1 & 1 & 1
			\end{pmatrix}\leadsto P_{\mf{R}'}^{-1}=\begin{pmatrix}
			1 & 1 & -1 \\
			-1 & 0 & 1 \\
			0 & -1 & 1
		\end{pmatrix}
	\end{gather*}
	Aplicando las ecuaciones del cambio de base:
	\begin{gather*}
		(\alpha,\beta,\gamma)_{\mc{B}_{\mf{R}}}\equiv P_{\mf{R}}^{-1}\begin{pmatrix}
			2 & 2 & 2
		\end{pmatrix}^t\equiv(2,-6,-4)_{\mc{B}_{\mf{R}}}\\
		(\alpha',\beta',\gamma')_{\mc{B}_{\mf{R}'}}\equiv P_{\mf{R}'}^{-1}\begin{pmatrix}
			2 & 2 & 2
		\end{pmatrix}^t\equiv (2,0,0)_{\mc{B}_{\mf{R}'}}
	\end{gather*}
	Así pues el punto $(2:2:2)$ escrito en la referencia cuya base asociada es la canónica (o un múltiplo suyo) se escribe, salvo múltiplos, como $(2:-6:-4)$ en base a la referencia $\mf{R}$ y como $(2:0:0)$ en base a la referencia $\mf{R}'$.
	
	Esto suele escribirse de la siguiente manera:
	\begin{gather*}
		x=(2:2:2)=\rho(2:-6:-4)_{\mf{R}}\ \forall \rho\in\R\smz\\
		x=(2:2:2)=\rho(2:0:0)_{\mf{R}'}\ \forall \rho\in\R\smz
	\end{gather*}
	Por ende, podemos escoger representaciones más o menos bonitas para nuestro punto dividiendo nuestras coordenadas homogéneas por el escalar no nulo que nos convenga. En ese caso:
	\begin{gather*}
		x=(1:-3:-2)_{\mf{R}}\\
		x=(1:0:0)_{\mf{R}'}
	\end{gather*}
	Esta última representación de $x$ en la referencia $\mf{R}'$ da que pensar, pues tiene aspecto de vector de la base canónica.
	
	 En efecto, cuando trabajábamos con espacios vectoriales sabíamos que las coordenadas en cierta base $\mc{B}$ del $i$--ésimo vector de $\mc{B}$ eran las correspodientes al $i$--esimo vector de la base canónica.
	 
	 En el contexto proyectivo esto sigue siendo cierto, basta darse cuenta de que $x$ es en realidad el primer punto de la referencia $\mf{R}$, por lo que admite una representación tan agradable. Este hecho, cuya comprobación se deja al lector, es de gran utilidad, por lo que será empleado sin previo aviso a lo largo del texto. 
\end{exa}